# ğŸš€ ComfyUI-LoraHelper

ä¸€ä¸ªä¸“ä¸º ComfyUI è®¾è®¡çš„ AI è‡ªåŠ¨ç”Ÿæˆæç¤ºè¯ã€è‡ªåŠ¨åŒ–æ‰¹é‡ç”Ÿå›¾ã€ LoRA è®­ç»ƒç´ ææ•´ç†å·¥å…·ã€‚é€šè¿‡é›†æˆå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œå®ç°ä»åŸå§‹ç´ æåˆ°ç»“æ„åŒ–è®­ç»ƒæ•°æ®çš„è‡ªåŠ¨åŒ–è½¬åŒ–ã€‚

An AI-powered tool designed for ComfyUI to automate prompt generation, batch image creation, and LoRA training dataset organization. By integrating Large Language Models (LLM), it achieves a seamless, automated transformation from raw materials to structured training datasets.

---

[English Version](#-core-features-en) | [ä¸­æ–‡è¯´æ˜](#-æ ¸å¿ƒåŠŸèƒ½)

<details>
<summary>ğŸŒ Click to expand English Version / ç‚¹å‡»å±•å¼€è‹±æ–‡ç‰ˆ</summary>

## ğŸ“¦ Core Features (EN)

- **Model Loader (GGUF_Loader)**: A dedicated loader optimized for GGUF architectures (e.g., Qwen3), featuring an integrated **VRAM Auto-Offload** mechanism to maximize generation efficiency.
- **User Interaction (Debug_Chat)**: Supports dynamic adjustment of core AI parameters such as `max_tokens`, `temperature`, etc.
    - Includes the following two primary modes:
    - **Debug Mode**: Analyzes `user_prompt` based on `system_command` instructions to output logical reasoning and thought processes, facilitating easier prompt debugging.
    - **Prompt_Enhance Mode**: AI creatively expands on user-provided materials following specific system instructions to generate high-quality, detail-rich visual descriptions.
- **Script Parsing (Output_Splitter)**: An automated extraction tool that leverages specific identifiers (**SECTION 1 / SECTION 2 / SECTION 3**) to parse prompts, LoRA training tags, and custom filenames from AI responses.
- **Automated Storage (All-In-One_Saver)**: A one-click solution to synchronize the saving of images, matching tag files (standardized for LoRA training), and comprehensive prompt logs.

## ğŸ“‚ Directory & Storage Specifications

- **LLM Models**: Please place your `.gguf` model files into the `ComfyUI/models/llm/` directory.
- **Asset Storage**: Files are saved to `ComfyUI/output/LoRA_Train_Data/` by default. Custom paths are supported.

## âœ‚ï¸ Splitter Execution Mechanism

The node identifies and segments AI output by recognizing specific semantic markers:
- `SECTION 1`: Extracted as the Image Generation Prompt (`gen_prompt`).
- `SECTION 2`: Extracted as LoRA Training Tags (`lora_tags`).
- `SECTION 3`: Extracted as the final Filename (`filename_final`).
*Fallback Mechanism: If no markers are detected, the system automatically captures the first natural paragraph to ensure the workflow remains uninterrupted.*

## ğŸ’¾ Saving Mechanism (Three-In-One)

Every save operation generates three synchronized files:
1. **Image (.png)**: Contains full generation metadata (workflow embedding is optional).
2. **Tags (.txt)**: Formatted as `trigger_word, tag1, tag2...`, ready for training.
3. **Logs (_log.txt)**: Records the original, complete AI response to preserve all raw prompt information for future reference.

## ğŸ› ï¸ Modular Installation

This project utilizes a decoupled architecture. Ensure the following files are present in the plugin folder:
- `__init__.py`: Plugin entry point and node registration.
- `LH_Chat.py`: Handles model loading and AI dialogue/enhancement logic.
- `LH_Utils.py`: Handles text splitting and file storage nodes.

## ğŸ’¡ Recommendation

**Combine with the Dynamic Prompts extension for maximum efficiency:**
- **Workflow**: Connect the `gen_prompt` output of this plugin to the input of a Dynamic Prompts node.
- **Advantage**: While the AI generates high-level scene descriptions, Dynamic Prompts can handle micro-variables via wildcards (e.g., `{red|blue} dress`), enabling infinite variations for batch generation from a single AI script.

</details>

---

## ğŸ“¦ æ ¸å¿ƒåŠŸèƒ½ (CN)

- **æ¨¡å‹åŠ è½½ (GGUF_Loader)**: ä¸“ä¸º Qwen3 ç­‰ GGUF æ¶æ„è®¾è®¡çš„åŠ è½½å™¨ï¼Œå†…ç½® VRAM è‡ªåŠ¨å¸è½½æœºåˆ¶ã€‚
- **ç”¨æˆ·äº¤äº’ (Debug_Chat)**: æ”¯æŒåŠ¨æ€è°ƒèŠ‚ `max_tokens`ã€`temperature` ç­‰ AI æ ¸å¿ƒå‚æ•°ã€‚
    - å¹¶ä¸”åŒ…æ‹¬ä»¥ä¸‹ä¸¤ä¸ªåŠŸèƒ½ï¼š
    - **Debug Mode**: æ ¹æ® system_command çš„æŒ‡ä»¤ï¼Œå¯¹ user_prompt è¿›è¡Œåˆ†æï¼Œç»™å‡ºæ€è€ƒç»“æœï¼Œæ–¹ä¾¿è°ƒè¯•ã€‚
    - **Prompt_Enhance Mode**: AI å°†æ ¹æ®ç”¨æˆ·æä¾›ç´ æè¿›è¡Œåˆ›æ„æ‰©å†™ï¼Œç”Ÿæˆæ›´ä¸°å¯Œçš„è§†è§‰æè¿°æç¤ºè¯ã€‚
- **å‰§æœ¬åˆ‡åˆ† (Output_Splitter)**: åŸºäºç‰¹å®šçš„åˆ†æ®µè¯ï¼ˆSECTION 1/2/3ï¼‰ä»è¾“å‡ºä¸­æˆªå–æç¤ºè¯ã€LoRA æ ‡ç­¾å’Œè‡ªå®šä¹‰æ–‡ä»¶åã€‚
- **è‡ªåŠ¨åŒ–å­˜ç›˜ (All-In-One_Saver)**: ä¸€é”®ä¿å­˜å›¾ç‰‡ã€åŒåæ ‡ç­¾æ–‡ä»¶ï¼ˆLoRA è®­ç»ƒæ‰“æ ‡ç”¨ï¼‰ä»¥åŠè¯¦ç»†çš„ prompt æ—¥å¿—ã€‚

## ğŸ“‚ ç›®å½•å­˜æ”¾è§„èŒƒ

- **LLM æ¨¡å‹**: è¯·å°† `.gguf` æ–‡ä»¶æ”¾å…¥ `ComfyUI/models/llm/` ç›®å½•ä¸‹ã€‚
- **ç´ æå­˜ç›˜**: é»˜è®¤ä¿å­˜åœ¨ `ComfyUI/output/LoRA_Train_Data/`ï¼Œæ”¯æŒè‡ªå®šä¹‰è·¯å¾„ã€‚

## âœ‚ï¸ Splitter è¿è¡Œæœºåˆ¶

èŠ‚ç‚¹é€šè¿‡è¯†åˆ« AI è¾“å‡ºä¸­çš„ç‰¹å®šæ ‡è®°è¿›è¡Œåˆ‡åˆ†ï¼š
- `SECTION 1`: æå–ä¸ºç”Ÿå›¾æç¤ºè¯ (gen_prompt)ã€‚
- `SECTION 2`: æå–ä¸º LoRA è®­ç»ƒæ ‡ç­¾ (lora_tags)ã€‚
- `SECTION 3`: æå–ä¸ºæœ€ç»ˆæ–‡ä»¶å (filename_final)ã€‚
*è‹¥æœªå‘ç°æ ‡è®°ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æŠ“å–é¦–ä¸ªè‡ªç„¶æ®µè¿›è¡Œä¿åº•ï¼Œç¡®ä¿æµç¨‹ä¸ä¸­æ–­ã€‚*

## ğŸ’¾ ä¿å­˜æœºåˆ¶ (ä¸‰ä½ä¸€ä½“)

æ¯æ¬¡ä¿å­˜å°†ç”Ÿæˆï¼š
1. **å›¾ç‰‡ (.png)**: åŒ…å«å®Œæ•´ç”Ÿå›¾å…ƒæ•°æ® (å·¥ä½œæµä¿å­˜å¯é€‰)ã€‚
2. **æ ‡ç­¾ (.txt)**: æ ¼å¼ä¸º `è§¦å‘è¯, æ ‡ç­¾1, æ ‡ç­¾2...`ã€‚
3. **æ—¥å¿— (_log.txt)**: è®°å½• AI çš„åŸå§‹å®Œæ•´æè¿°ï¼Œæ–¹ä¾¿æ•´ç†æ–‡ç”Ÿå›¾åŸå§‹ä¿¡æ¯ã€‚

## ğŸ› ï¸ æ¨¡å—åŒ–å®‰è£…

æœ¬é¡¹ç›®é‡‡ç”¨è§£è€¦æ¶æ„ï¼Œè¯·ç¡®ä¿æ–‡ä»¶å¤¹å†…åŒ…å«ä»¥ä¸‹æ–‡ä»¶ï¼š
- `__init__.py`: æ’ä»¶å…¥å£ä¸èŠ‚ç‚¹æ³¨å†Œã€‚
- `LH_Chat.py`: å¤„ç†æ¨¡å‹åŠ è½½ä¸ AI å¯¹è¯åŠå¢å¼ºé€»è¾‘ã€‚
- `LH_Utils.py`: å¤„ç†æ–‡æœ¬åˆ‡åˆ†ä¸æ–‡ä»¶å­˜ç›˜èŠ‚ç‚¹ã€‚

## ğŸ’¡ ä½¿ç”¨å»ºè®®

**å»ºè®®é…åˆ Dynamic Prompts æ’ä»¶ä½¿ç”¨ï¼š**
- **æ“ä½œæ–¹å¼**: å°†æœ¬æ’ä»¶è¾“å‡ºçš„ `gen_prompt` æ¥å…¥ Dynamic Prompts èŠ‚ç‚¹çš„è¾“å…¥ç«¯ã€‚
- **æ ¸å¿ƒä¼˜åŠ¿**: AI è´Ÿè´£ç”Ÿæˆåœºæ™¯æè¿°ï¼ŒDynamic Prompts è´Ÿè´£å¯¹é€šé…ç¬¦å˜é‡è¿›è¡Œæ›¿æ¢ï¼ˆå¦‚ `{red|blue} dress`ï¼‰ï¼Œå®ç°å•æ¬¡ AI å‰§æœ¬ä¸‹çš„æ— é™å˜ä½“æ‰¹é‡ç”Ÿå›¾ã€‚